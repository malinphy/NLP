# -*- coding: utf-8 -*-
"""SciBERT demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUoQiRKgwlTfZv44ZT8vrJqtSY9B2sXE
"""

!pip install --quiet datasets
import pandas as pd 
import numpy as np 
# from google.colab import drive
# drive.mount('/content/drive')
import json
import os 
import gzip
import datasets 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras import layers, Input, Model
from tensorflow.keras.layers import *
import tensorflow_hub as hub 

from sklearn.metrics import confusion_matrix

eli5 = datasets.load_dataset('eli5', split = 'train_eli5')

use_hub = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4") ## universal sentence encoder model

# title 
# selftext
# answer
#
eli5

print('title length :', len(eli5['title']))
print('selftext length :', len(eli5['selftext']))
print('answers length :', len(eli5['answers']))

df = pd.DataFrame({'title':eli5['title'], 'selftext':eli5['selftext'], 'answer':eli5['answers']})
### as you can see from the data, dataset is corrupted, to eliminate
df.head(4)

answer_len = []
first_answer = []
for i in range(len(df)):
    answer_len.append(len(df['answer'][i]['text']))
    first_answer.append(df['answer'][i]['text'][0])

df['first_answer'] = first_answer

unique_answer = df['first_answer'].unique()
num_unique_answer = len(unique_answer)

unique_questions = df['title'].unique()
num_unique_questions =  len(unique_questions)

print('number of unique answers',num_unique_answer)
print('number of unique questions',num_unique_questions)

neg_pos = []
neg_title = []
neg_answer = []
for i in range(len(df)):
    x = np.random.randint(0, len(df))
    neg_pos.append(x)
    neg_title.append(df['title'][x])
    neg_answer.append(df['first_answer'][x])

df['neg_title'] = neg_title
df['neg_answer'] = neg_answer


def distance_calc(y_true, y_pred):
    anchor, positive, negative = tf.split(y_pred, 3, axis=1)
    ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)
    an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)
    loss = ap_distance - an_distance
    margin = 0
    loss = tf.maximum(loss + margin, 0.0)
    return loss

title_batch = tf.data.Dataset.from_tensor_slices(df['title']).batch(32)
pos_batch = tf.data.Dataset.from_tensor_slices(df['first_answer']).batch(32)
neg_batch = tf.data.Dataset.from_tensor_slices(df['neg_answer']).batch(32)

first_anc_emb = []
first_pos_emb = []
first_neg_emb = []

for i in title_batch:
    first_anc_emb.append(np.array(use_hub(i)))

for i in pos_batch:
    first_pos_emb.append(np.array(use_hub(i)))

for i in neg_batch:
    first_neg_emb.append(np.array(use_hub(i)))

first_anc_emb = np.concatenate(np.array(first_anc_emb), axis = 0)
first_pos_emb = np.concatenate(np.array(first_pos_emb), axis = 0)
first_neg_emb = np.concatenate(np.array(first_neg_emb), axis = 0)

anc_inp = Input(shape =(), dtype = tf.string, name = 'anchor_input')
pos_inp = Input(shape =(), dtype = tf.string, name = 'positive_input')
neg_inp = Input(shape =(), dtype = tf.string, name = 'negative_input')

use_emb = hub.KerasLayer(use_hub, trainable =True)
anc_emb = use_emb(anc_inp)
pos_emb = use_emb(pos_inp)
neg_emb = use_emb(neg_inp)

final = tf.keras.layers.Concatenate(axis=-1)([anc_emb, pos_emb, neg_emb])

triplet_model = Model(inputs = [anc_inp, pos_inp, neg_inp], outputs = final)

triplet_model.compile(
    optimizer = 'Adam',
    loss = distance_calc
)
y_dummy = np.ones(len(df)).reshape(-1,1)
triplet_model.fit([np.array(df['title']),
                   np.array(df['first_answer']),
                   np.array(df['neg_answer'])
                   ],
                   y_dummy,
                   epochs = 1,
                  )

second_anc_emb = []
second_pos_emb = []
second_neg_emb = []

for i in title_batch:
    second_anc_emb.append(np.array(use_hub(i)))

for i in pos_batch:
    second_pos_emb.append(np.array(use_hub(i)))

for i in neg_batch:
    second_neg_emb.append(np.array(use_hub(i)))

second_anc_emb = np.concatenate(np.array(second_anc_emb), axis = 0)
second_pos_emb = np.concatenate(np.array(second_pos_emb), axis = 0)
second_neg_emb = np.concatenate(np.array(second_neg_emb), axis = 0)

first = tf.keras.layers.Dot(axes = 1, normalize = True)([first_anc_emb,first_pos_emb])
second = tf.keras.layers.Dot(axes = 1, normalize = True)([second_anc_emb,second_pos_emb])

for i in range(10):
    print(first[i], second[i])
